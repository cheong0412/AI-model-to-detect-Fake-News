import pandas as pd
from konlpy.tag import Okt


filepath_train = './fakenews_train.csv'
filepath_test = './fakenews_test.csv'

# ë°ì´í„° í”„ë ˆì„ ë§Œë“¤ê¸°
fakenews_train_pd = pd.read_csv(filepath_train)
fakenews_test_pd = pd.read_csv(filepath_test)

okt = Okt()

def preprocess_and_save(df, stopwords_path, output_csv_path, text_columns=['title', 'content']):
    """
    1. ë¶ˆìš©ì–´ txt ë¶ˆëŸ¬ì˜¤ê¸°
    2. Oktë¡œ ëª…ì‚¬ + ë™ì‚¬ ì¶”ì¶œ (ë¶ˆìš©ì–´ ì œê±°)
    3. ê¸°ì¡´ ì»¬ëŸ¼ ë®ì–´ì“°ê¸° (1000í–‰ë§ˆë‹¤ ì§„í–‰ ìƒí™© ì¶œë ¥)
    4. CSVë¡œ ì €ì¥
    """
    # 1. ë¶ˆìš©ì–´ ì½ê¸°
    with open(stopwords_path, 'r', encoding='utf-8') as f:
        stopwords = [line.strip() for line in f if line.strip()]

    # 2. ì „ì²˜ë¦¬ í•¨ìˆ˜ ì •ì˜
    def extract(text):
        tagged = okt.pos(str(text), stem=True)
        tokens = [word for word, pos in tagged if pos in ['Noun', 'Verb'] and word not in stopwords]
        return tokens  # ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ë°˜í™˜

    # 3. ì „ì²˜ë¦¬ ìˆ˜í–‰ (1000í–‰ë§ˆë‹¤ ì¶œë ¥)
    for col in text_columns:
        print(f"ğŸ”§ '{col}' ì „ì²˜ë¦¬ ì¤‘...")
        processed_col = []
        for i, text in enumerate(df[col]):
            tokens = extract(text)
            processed_col.append(tokens)  # í† í°í™”ëœ ê²°ê³¼ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ì €ì¥
            if (i + 1) % 1000 == 0:
                print(f"  âœ… {col} ì²˜ë¦¬ ì¤‘: {i + 1} / {len(df)}")
        df[col] = processed_col  # ì „ì²˜ë¦¬ëœ ë¦¬ìŠ¤íŠ¸ë¥¼ ì—´ì— ì €ì¥

    # 4. ì €ì¥
    df.to_csv(output_csv_path, index=False, encoding='utf-8-sig')
    print(f"\nâœ… ì „ì²˜ë¦¬ ì™„ë£Œ & ì €ì¥ë¨ â†’ {output_csv_path}")

    return df

# ------------------------------------------------------------------------------------------------------------

stopwords_file = './stopword.txt'
output_file_train = 'fakenews_preprocessed_trian2_.csv'
output_file_test = 'fakenews_preprocessed_test2_.csv'

# ------------------------------------------------------------------------------------------------------------

# í•¨ìˆ˜ ì‹¤í–‰
# fakenews_train_pd = preprocess_and_save(fakenews_train_pd, stopwords_path=stopwords_file, output_csv_path=output_file_train)
fakenews_test_pd = preprocess_and_save(fakenews_test_pd, stopwords_path=stopwords_file, output_csv_path=output_file_test)
